{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/digit-recognizer/train.csv\n",
      "/kaggle/input/digit-recognizer/sample_submission.csv\n",
      "/kaggle/input/digit-recognizer/test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "  rotation_range=10,\n",
    "  zoom_range=0.1,\n",
    "  width_shift_range=0.1,\n",
    "  height_shift_range=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../input/digit-recognizer/train.csv\")\n",
    "test = pd.read_csv(\"../input/digit-recognizer/test.csv\")\n",
    "ssub = pd.read_csv(\"../input/digit-recognizer/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "\n",
       "[2 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      0\n",
       "1        2      0\n",
       "2        3      0\n",
       "3        4      0\n",
       "4        5      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.label\n",
    "X = train.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0\n",
    "test = test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy().reshape(-1, 28,28,1)\n",
    "test = test.to_numpy().reshape(-1, 28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[0][:,:,0], cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "630/630 [==============================] - 13s 21ms/step - loss: 0.5581 - accuracy: 0.8176\n",
      "1 **********\n",
      "[[ 984    0    2    3    0    9    1    0   33    1]\n",
      " [   0 1126   11    6    1    0    1   12   12    2]\n",
      " [   0    0 1019   17    0    0    1    2    6    0]\n",
      " [   0    0    4 1074    0    2    0    2    5    1]\n",
      " [   0    0    2    1  978    0    4    0    4   29]\n",
      " [   1    0    0   16    0  926    0    0    6    0]\n",
      " [   3    1    0    0    0    2 1020    0    9    0]\n",
      " [   0    0   11   33    0    0    0 1045    4    8]\n",
      " [   0    1    3    3    0    1    0    2 1003    3]\n",
      " [   3    0    1    4    3   15    0    8   12 1001]]\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 12s 19ms/step - loss: 0.5671 - accuracy: 0.8143\n",
      "2 **********\n",
      "[[1022    0    0    0    0    1    4    0    6    0]\n",
      " [   0 1153    7    3    0    0    0    2    6    0]\n",
      " [   1    2 1015    6    0    0    1   10    9    0]\n",
      " [   0    0    5 1070    0    9    0    0    1    3]\n",
      " [   1    0    2    0  991    0    2    0    5   17]\n",
      " [   0    0    0    2    0  938    4    0    3    2]\n",
      " [   6    0    0    0    2    1 1020    0    5    0]\n",
      " [   0    1    5    1    5    0    0 1081    0    7]\n",
      " [   1    0    3    2    2    0    2    1 1001    4]\n",
      " [   4    0    0    0    6    1    1    2    4 1029]]\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 11s 17ms/step - loss: 0.5185 - accuracy: 0.8314\n",
      "3 **********\n",
      "[[1025    0    0    0    1    1    1    0    5    0]\n",
      " [   0 1161    3    2    0    0    0    3    2    0]\n",
      " [   1    5 1027    0    0    0    0    3    8    0]\n",
      " [   1    0    7 1052    0    4    0   13   10    1]\n",
      " [   0    2    0    0  989    0    1    2    4   20]\n",
      " [   0    1    0    5    3  927    2    0    5    6]\n",
      " [   5    1    0    0    1    1 1022    0    4    0]\n",
      " [   2    0    3    0    2    0    0 1084    1    8]\n",
      " [   3    4    1    0    3    2    1    1 1000    1]\n",
      " [   2    1    1    1    3    2    0    7    4 1026]]\n",
      "Epoch 1/1\n",
      "631/631 [==============================] - 11s 17ms/step - loss: 0.5387 - accuracy: 0.8245\n",
      "4 **********\n",
      "[[1021    0    0    0    1    0   10    0    1    0]\n",
      " [   0 1156    9    1    2    0    0    1    2    0]\n",
      " [   1    4 1021    2    0    0    1    9    5    1]\n",
      " [   0    0   21 1049    0    3    0    8    3    3]\n",
      " [   2    3    0    0 1009    0    0    0    0    4]\n",
      " [   2    0    0    1    1  935    7    1    0    1]\n",
      " [   1    0    1    0    4    3 1024    0    1    0]\n",
      " [   1    6   17    1    4    0    0 1060    2    9]\n",
      " [   2    4    5    0    3    0    4    0  991    6]\n",
      " [   5    4    0    3   18    9    0    7    4  997]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAACrRJREFUeJzt3V+o33d9x/Hny5P0T+o6lQ2hSVhT6myL6FLOpFrmRSuoUyzILiqrY97kZtoqgtTBJmy3UtQhQqh6Y7AXsTCRYh1TwV0sNE3LbHraEVKXxlbNGKtSsEna9y7OEWKXnN83Od+v33PePh9QyO/020/fnP6e/X5/v/P9fU6qCkk9vWbuASRNx8ClxgxcaszApcYMXGrMwKXGDFxqzMClxgxcamzbFIte/YZt9cad20df92dPXDn6mtJW9Cte5HS9lEXHTRL4G3du575/vn70db94/Q2jr6mJvWZpmnVfeXmadbeIQ/Wvg47zEl1qzMClxgxcaszApcYMXGrMwKXGBgWe5L1Jnk5yLMm9Uw8laRwLA0+yBHwJeB9wE/DhJDdNPZikjRtyBn87cKyqjlfVaeAB4I5px5I0hiGB7wSePefxybWv/YYk+5IcTnL4hf/53b7LSNoshgR+vvtd/99WrFW1v6qWq2r5998w0e2Jki7KkMBPArvPebwLeG6acSSNaUjgjwBvSrInyWXAncC3ph1L0hgWfpqsqs4m+RjwMLAEfLWqjk4+maQNG/Rx0ap6CHho4lkkjcw72aTGDFxqzMClxgxcaszApcYm2XTxZ09cOckGiQ8/9/joawK8Z+fe8Rf1966v+h3fHHFunsGlxgxcaszApcYMXGrMwKXGDFxqzMClxgxcaszApcYMXGrMwKXGDFxqzMClxgxcaszApcYMXGrMwKXGDFxqzMClxgxcaszApcYm2VV1Ku+55k8mWffuYyujrznFrrI6R873a+s3qRl32PUMLjVm4FJjBi41ZuBSYwYuNWbgUmMLA0+yO8n3k6wkOZrknt/GYJI2bsjPwc8Cn6qqI0l+D3g0yb9U1ZMTzyZpgxaewavq+ao6svbnXwIrwM6pB5O0cRf1GjzJtcBe4NAUw0ga1+BbVZO8Fvgm8Imq+sV5/v4+YB/AFewYbUBJl27QGTzJdlbjPlBVD57vmKraX1XLVbW8ncvHnFHSJRryLnqArwArVXXf9CNJGsuQM/itwEeA25I8vvbXn088l6QRLHwNXlX/Bmyhz+ZJ+jXvZJMaM3CpMQOXGjNwqTEDlxrbUpsuTuWfbnzr6Gv+/fF/H31NgH+47uZJ1hWzbo44Fc/gUmMGLjVm4FJjBi41ZuBSYwYuNWbgUmMGLjVm4FJjBi41ZuBSYwYuNWbgUmMGLjVm4FJjBi41ZuBSYwYuNWbgUmMGLjVm4FJj7qoK1JnTo6851e6n+/7z+CTr7v/j6yZZdzINd0CdgmdwqTEDlxozcKkxA5caM3CpMQOXGjNwqbHBgSdZSvJYkm9POZCk8VzMGfweYGWqQSSNb1DgSXYB7wfun3YcSWMaegb/PPBp4JULHZBkX5LDSQ6f4aVRhpO0MQsDT/IB4OdV9eh6x1XV/qparqrl7Vw+2oCSLt2QM/itwAeT/Bh4ALgtydcnnUrSKBYGXlWfqapdVXUtcCfwvaq6a/LJJG2YPweXGruoz4NX1Q+AH0wyiaTReQaXGjNwqTEDlxozcKkxA5cac1fVLWaq3U//7D9+Ncm6P3zblZOs666qw3gGlxozcKkxA5caM3CpMQOXGjNwqTEDlxozcKkxA5caM3CpMQOXGjNwqTEDlxozcKkxA5caM3CpMQOXGjNwqTEDlxozcKkxA5cac1dVAfDDt14xybp3H1uZZN0vXn/DJOt24xlcaszApcYMXGrMwKXGDFxqzMClxgYFnuR1SQ4meSrJSpJ3TD2YpI0b+nPwLwDfqaq/SHIZsGPCmSSNZGHgSa4G3gX8NUBVnQZOTzuWpDEMuUS/DjgFfC3JY0nuT3LVxHNJGsGQwLcBNwNfrqq9wIvAva8+KMm+JIeTHD7DSyOPKelSDAn8JHCyqg6tPT7IavC/oar2V9VyVS1v5/IxZ5R0iRYGXlU/BZ5N8ua1L90OPDnpVJJGMfRd9I8DB9beQT8OfHS6kSSNZVDgVfU4sDzxLJJG5p1sUmMGLjVm4FJjBi41ZuBSYwYuNba1dlVNpll2aWn0Nevs2dHX3Iqm2v30H595ZPQ1/27Pn46+JjDN87aGHeYZXGrMwKXGDFxqzMClxgxcaszApcYMXGrMwKXGDFxqzMClxgxcaszApcYMXGrMwKXGDFxqzMClxgxcaszApcYMXGrMwKXGttamizVwp7mLXfbllydZV9OZYoPEv3zq5OhrAhy4cfck6w7hGVxqzMClxgxcaszApcYMXGrMwKXGDFxqbFDgST6Z5GiSJ5J8I8kVUw8maeMWBp5kJ3A3sFxVbwGWgDunHkzSxg29RN8GXJlkG7ADeG66kSSNZWHgVfUT4HPACeB54IWq+u6rj0uyL8nhJIfP8NL4k0q6aEMu0V8P3AHsAa4Brkpy16uPq6r9VbVcVcvbuXz8SSVdtCGX6O8GnqmqU1V1BngQeOe0Y0kaw5DATwC3JNmRJMDtwMq0Y0kaw5DX4IeAg8AR4Edr/8z+ieeSNIJBnwevqs8Cn514Fkkj8042qTEDlxozcKkxA5caM3Cpsel2VU3GX3OiXVUnW3cC2TbNf7LJdpad6ns7wfPrwA27Rl8T4K+ePjH6msc+dHrQcZ7BpcYMXGrMwKXGDFxqzMClxgxcaszApcYMXGrMwKXGDFxqzMClxgxcaszApcYMXGrMwKXGDFxqzMClxgxcaszApcYMXGrMwKXGUhPsepnkFPBfAw79A+C/Rx9gOltp3q00K2yteTfDrH9UVX+46KBJAh8qyeGqWp5tgIu0lebdSrPC1pp3K83qJbrUmIFLjc0d+P6Z//0XayvNu5Vmha0175aZddbX4JKmNfcZXNKEZgs8yXuTPJ3kWJJ755pjkSS7k3w/yUqSo0numXumIZIsJXksybfnnmU9SV6X5GCSp9a+x++Ye6b1JPnk2vPgiSTfSHLF3DOtZ5bAkywBXwLeB9wEfDjJTXPMMsBZ4FNVdSNwC/A3m3jWc90DrMw9xABfAL5TVTcAb2MTz5xkJ3A3sFxVbwGWgDvnnWp9c53B3w4cq6rjVXUaeAC4Y6ZZ1lVVz1fVkbU//5LVJ+DOeadaX5JdwPuB++eeZT1JrgbeBXwFoKpOV9X/zjvVQtuAK5NsA3YAz808z7rmCnwn8Ow5j0+yyaMBSHItsBc4NO8kC30e+DTwytyDLHAdcAr42trLifuTXDX3UBdSVT8BPgecAJ4HXqiq78471frmCvx8v719U7+dn+S1wDeBT1TVL+ae50KSfAD4eVU9OvcsA2wDbga+XFV7gReBzfx+zOtZvdLcA1wDXJXkrnmnWt9cgZ8Edp/zeBeb+FInyXZW4z5QVQ/OPc8CtwIfTPJjVl/63Jbk6/OOdEEngZNV9esrooOsBr9ZvRt4pqpOVdUZ4EHgnTPPtK65An8EeFOSPUkuY/WNim/NNMu6koTV14grVXXf3PMsUlWfqapdVXUtq9/X71XVpjzLVNVPgWeTvHntS7cDT8440iIngFuS7Fh7XtzOJn5TEFYvkX7rqupsko8BD7P6TuRXq+roHLMMcCvwEeBHSR5f+9rfVtVDM87UyceBA2v/oz8OfHTmeS6oqg4lOQgcYfWnK4+xye9q8042qTHvZJMaM3CpMQOXGjNwqTEDlxozcKkxA5caM3Cpsf8DzNpKA/YTfrgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=4, shuffle=True, random_state=2)\n",
    "i = 1\n",
    "for sub_train, sub_test in kfold.split(X, y):\n",
    "    yy = to_categorical(y.copy(), num_classes = 10)\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X.shape[1:]))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(rate=0.25))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(rate=0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer='adam', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    model.fit_generator(datagen.flow(X[sub_train], yy[sub_train], batch_size=50), epochs=1, verbose=1)\n",
    "    \n",
    "    y_pred = model.predict(X[sub_test])\n",
    "    \n",
    "    Y_pred_classes = np.argmax(y_pred,axis = 1) \n",
    "    # Convert validation observations to one hot vectors\n",
    "    Y_true = np.argmax(yy[sub_test],axis = 1) \n",
    "    # compute the confusion matrix\n",
    "    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n",
    "#     cm = confusion_matrix(yy[test], y_pred)\n",
    "\n",
    "    print(i,'*'*10)\n",
    "    print(confusion_mtx)\n",
    "    plt.imshow(confusion_mtx, interpolation='nearest')\n",
    "    i += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-fold accuracy: \n",
    "Epoch 1/1\n",
    "630/630 [==============================] - 11s 17ms/step - loss: 0.5285 - accuracy: 0.8277\n",
    "1 **********\n",
    "Epoch 1/1\n",
    "630/630 [==============================] - 11s 17ms/step - loss: 0.5680 - accuracy: 0.8135\n",
    "2 **********\n",
    "Epoch 1/1\n",
    "630/630 [==============================] - 11s 17ms/step - loss: 0.5427 - accuracy: 0.8235\n",
    "3 **********\n",
    "Epoch 1/1\n",
    "631/631 [==============================] - 11s 17ms/step - loss: 0.5442 - accuracy: 0.8218\n",
    "4 **********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "420/420 [==============================] - 13s 31ms/step - loss: 0.5646 - accuracy: 0.8164\n",
      "Epoch 2/5\n",
      "420/420 [==============================] - 13s 31ms/step - loss: 0.1674 - accuracy: 0.9505\n",
      "Epoch 3/5\n",
      "420/420 [==============================] - 13s 31ms/step - loss: 0.1221 - accuracy: 0.9645\n",
      "Epoch 4/5\n",
      "420/420 [==============================] - 13s 31ms/step - loss: 0.0992 - accuracy: 0.9706\n",
      "Epoch 5/5\n",
      "420/420 [==============================] - 13s 31ms/step - loss: 0.0887 - accuracy: 0.9734\n"
     ]
    }
   ],
   "source": [
    "yy = to_categorical(y.copy(), num_classes = 10)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X.shape[1:]))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit_generator(datagen.flow(X, yy, batch_size=100), epochs=5, verbose=1)\n",
    "\n",
    "y_pred = model.predict(test)\n",
    "\n",
    "y_submission = np.argmax(y_pred,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      0\n",
       "4        5      3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({'ImageId': range(1,28001), 'Label':y_submission})\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('cnn_submission_01.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
